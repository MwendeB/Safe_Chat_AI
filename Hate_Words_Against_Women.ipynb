{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMiY9k3EqbcpNauI/iJ2+Eb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MwendeB/Safe_Chat_AI/blob/main/Hate_Words_Against_Women.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers torch flask flask-ngrok pyngrok flask-cors\n",
        "\n",
        "\n",
        "# Import statements\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from pyngrok import ngrok  # <-- You were missing this\n",
        "\n",
        "\n",
        "# Set your ngrok auth token\n",
        "ngrok.set_auth_token(\"37FSjTtW5quWgIlPr8vXOxKdbBU_2zK9RtsG4NfxDHhXDmtX\")"
      ],
      "metadata": {
        "id": "bMONp-SorAKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FLASK APP SETUP#\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"unitary/toxic-bert\",\n",
        "    return_all_scores=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "xOjEBzChvdO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_harm_words = [\n",
        "    \"bitch\",\n",
        "    \"sheâ€™s ugly\",\n",
        "    \"women are stupid\",\n",
        "    \"girls are weak\",\n",
        "    \"she should stay in the kitchen\"\n",
        "    \"she looks like a man\"\n",
        "\n",
        "]\n"
      ],
      "metadata": {
        "id": "5fha0Lc2ikmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_gender_harm(text):\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Keyword-based flag\n",
        "    keyword_flag = any(word in text_lower for word in gender_harm_words)\n",
        "\n",
        "    # Model prediction\n",
        "    results = classifier(text)[0]\n",
        "\n",
        "    # Toxicity score (max score of any harmful label)\n",
        "    toxicity_score = max(r[\"score\"] for r in results)\n",
        "\n",
        "    if keyword_flag or toxicity_score > 0.7:\n",
        "        return {\n",
        "            \"status\": \"harmful\",\n",
        "            \"action\": [\"Block message\", \"Report content\", \"Alert moderator\"],\n",
        "            \"toxicity_score\": round(toxicity_score, 2)\n",
        "        }\n",
        "    elif toxicity_score > 0.4:\n",
        "        return {\n",
        "            \"status\": \"warning\",\n",
        "            \"action\": [\"Suggest rephrasing\", \"Educate user\"],\n",
        "            \"toxicity_score\": round(toxicity_score, 2)\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"status\": \"safe\",\n",
        "            \"action\": [\"Allow\"],\n",
        "            \"toxicity_score\": round(toxicity_score, 2)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Ym2Ns9x6lwut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of a simple placeholder function\n",
        "def check_gender_harm(text):\n",
        "    # Very basic check for demonstration\n",
        "    harmful_words = [\"stupid\", \"useless\", \"weak\"]\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    for word in harmful_words:\n",
        "        if word in text_lower:\n",
        "            return \"Harmful content detected\"\n",
        "    return \"Safe content\"\n",
        "\n",
        "# Test it\n",
        "text = \"Women are stupid and should not lead\"\n",
        "print(check_gender_harm(text))\n",
        "\n"
      ],
      "metadata": {
        "id": "VLjivFbWFKMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install (run once per session)\n",
        "!pip install flask flask-cors pyngrok --upgrade\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ðŸ” Set your ngrok authtoken (replace with your real one)\n",
        "ngrok.set_auth_token(\"37NA3w0ehuqqChBe3aKntWzcQxh_6gGa1p5DWdeiMzpCYci9T\")\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Start ngrok tunnel FIRST\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"âœ… PUBLIC NGROK URL:\", public_url)\n",
        "\n",
        "# Simple gender-harm checker\n",
        "def check_gender_harm(text):\n",
        "    harmful_words = [\"bitch\", \"slut\", \"women are stupid\"]\n",
        "    if any(w in text.lower() for w in harmful_words):\n",
        "        return {\n",
        "            \"status\": \"harmful\",\n",
        "            \"next_steps\": [\"Block message\", \"Report content\", \"Alert moderator\"]\n",
        "        }\n",
        "    return {\"status\": \"safe\", \"next_steps\": [\"Allow\"]}\n",
        "\n",
        "# API endpoint\n",
        "@app.route(\"/safety-check\", methods=[\"POST\"])\n",
        "def safety_check():\n",
        "    data = request.get_json(force=True)\n",
        "    text = data.get(\"text\", \"\")\n",
        "    return jsonify(check_gender_harm(text))\n",
        "\n",
        "# Run Flask\n",
        "app.run(host=\"0.0.0.0\", port=5000)\n",
        "public_url = ngrok.connect(addr=5000, proto=\"http\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NrrxOw28WBkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91b7266-078d-4dd0-b761-e98c9f2f8b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "âœ… PUBLIC NGROK URL: NgrokTunnel: \"https://gretta-unimpressed-noncommercially.ngrok-free.dev\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:01:42] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:01:43] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:02:11] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:02:11] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:02:47] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:02:48] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:03:12] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:03:13] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:03:17] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:03:37] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:03:37] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:04:40] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:04:40] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:05:06] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:05:06] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:05:26] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:05:27] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:10:24] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:10:25] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:10:50] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:10:51] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:11:14] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:11:15] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:11:27] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:11:28] \"POST /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:13:25] \"OPTIONS /safety-check HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [28/Dec/2025 13:13:26] \"POST /safety-check HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}